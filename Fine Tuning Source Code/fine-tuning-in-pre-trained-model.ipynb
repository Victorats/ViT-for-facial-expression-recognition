{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom transformers import ViTForImageClassification\nimport os\nimport time\nfrom tqdm import tqdm  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndata_dir = \"/kaggle/input/fer2013\"  \nnum_classes = 7  \nbatch_size = 32\n\n\ntransform = transforms.Compose([\n    transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),  \n    transforms.CenterCrop(224),  # Recorte central\n    transforms.ToTensor(),  # Converter para tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n])\n\n\ndatasets_dict = {\n    \"train\": datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform),\n    \"val\": datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)  \n}\n\ndataloaders = {\n    phase: DataLoader(datasets_dict[phase], batch_size=batch_size, shuffle=(phase == \"train\"), num_workers=4)\n    for phase in [\"train\", \"val\"]\n}\n\ndata_sizes = {phase: len(datasets_dict[phase]) for phase in [\"train\", \"val\"]}\nprint(f\"Tamanho do conjunto de treinamento: {data_sizes['train']}\")\nprint(f\"Tamanho do conjunto de validação: {data_sizes['val']}\")\n\nmodel = ViTForImageClassification.from_pretrained(\n    \"google/vit-base-patch16-224-in21k\",  \n    num_labels=num_classes  \n)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n\ndef train_and_validate(model, dataloaders, criterion, optimizer, num_epochs=10, checkpoint_dir=\"/kaggle/working/checkpoints\"):\n    os.makedirs(checkpoint_dir, exist_ok=True)  \n    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n    \n    for epoch in range(num_epochs):\n        print(f\"\\epoca {epoch + 1}/{num_epochs}\")\n        print(\"-\" * 40)\n        epoch_start = time.time()\n        \n        for phase in [\"train\", \"val\"]:\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n            \n            running_loss = 0.0\n            running_corrects = 0\n            progress_bar = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Processando\")\n            \n            for inputs, labels in progress_bar:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == \"train\"):\n                    outputs = model(inputs).logits\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n                    \n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n                \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                progress_bar.set_postfix(loss=loss.item())\n            \n            epoch_loss = running_loss / data_sizes[phase]\n            epoch_acc = running_corrects.double() / data_sizes[phase]\n            history[f\"{phase}_loss\"].append(epoch_loss)\n            history[f\"{phase}_acc\"].append(epoch_acc)\n            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n        \n        epoch_end = time.time()\n        print(f\"Tempo de execução da epocj levou: {epoch_end - epoch_start:.2f} segundos\")\n        \n        if (epoch + 1) % 5 == 0:\n            checkpoint_path = os.path.join(checkpoint_dir, f\"vit_epoch_{epoch + 1}.pt\")\n            torch.save(model.state_dict(), checkpoint_path)\n            print(f\"Checkpoint salvo em: {checkpoint_path}\")\n    \n    print(\"\\nTreinamento concluído!\")\n    return history\n\nhistory = train_and_validate(model, dataloaders, criterion, optimizer, num_epochs=10)\noutput_dir = \"/kaggle/working/vit-fine-tuned-facial-expressions\"\nos.makedirs(output_dir, exist_ok=True)  # Garantir que o diretório exista\nmodel.save_pretrained(output_dir)\nprint(f\"Modelo salvo com sucesso em: {output_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:52:40.701582Z","iopub.execute_input":"2024-12-18T08:52:40.701831Z","iopub.status.idle":"2024-12-18T11:47:28.028749Z","shell.execute_reply.started":"2024-12-18T08:52:40.701802Z","shell.execute_reply":"2024-12-18T11:47:28.026263Z"}},"outputs":[{"name":"stdout","text":"Usando dispositivo: cuda\nTamanho do conjunto de treinamento: 28709\nTamanho do conjunto de validação: 7178\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09226be6fdd14167b72f561cdf2a4f99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"146c93733b444b9f9338e5e67b2eb6e3"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nÉpoca 1/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando:   0%|          | 0/898 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nTrain Processando: 100%|██████████| 898/898 [15:51<00:00,  1.23it/s, loss=1.4]  /opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nTrain Processando: 100%|██████████| 898/898 [15:51<00:00,  1.06s/it, loss=1.4]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0728 Acc: 0.6022\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.77it/s, loss=0.383]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.9468 Acc: 0.6447\nTempo de execução da época: 1032.99 segundos\n\nÉpoca 2/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:01<00:00,  1.07s/it, loss=0.724]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8037 Acc: 0.7069\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.75it/s, loss=0.0765]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8932 Acc: 0.6799\nTempo de execução da época: 1043.67 segundos\n\nÉpoca 3/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.605]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6278 Acc: 0.7727\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.76it/s, loss=0.118]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8946 Acc: 0.6832\nTempo de execução da época: 1043.80 segundos\n\nÉpoca 4/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.564]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4479 Acc: 0.8452\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.76it/s, loss=0.196]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.9544 Acc: 0.6871\nTempo de execução da época: 1043.78 segundos\n\nÉpoca 5/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.147] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2940 Acc: 0.9007\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.76it/s, loss=0.133]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.0299 Acc: 0.6881\nTempo de execução da época: 1043.69 segundos\nCheckpoint salvo em: /kaggle/working/checkpoints/vit_epoch_5.pt\n\nÉpoca 6/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.271] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2179 Acc: 0.9269\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.77it/s, loss=0.231] \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.0815 Acc: 0.6980\nTempo de execução da época: 1043.71 segundos\n\nÉpoca 7/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.00766]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1515 Acc: 0.9515\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.77it/s, loss=0.0234]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.2206 Acc: 0.6847\nTempo de execução da época: 1043.34 segundos\n\nÉpoca 8/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.02]   \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1254 Acc: 0.9596\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.76it/s, loss=0.543] \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.2952 Acc: 0.6874\nTempo de execução da época: 1044.12 segundos\n\nÉpoca 9/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.213]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1099 Acc: 0.9635\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.77it/s, loss=0.0411]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.2809 Acc: 0.6977\nTempo de execução da época: 1043.74 segundos\n\nÉpoca 10/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Processando: 100%|██████████| 898/898 [16:02<00:00,  1.07s/it, loss=0.546]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1005 Acc: 0.9656\n","output_type":"stream"},{"name":"stderr","text":"Val Processando: 100%|██████████| 225/225 [01:21<00:00,  2.76it/s, loss=0.559]  \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 1.3895 Acc: 0.6806\nTempo de execução da época: 1043.87 segundos\nCheckpoint salvo em: /kaggle/working/checkpoints/vit_epoch_10.pt\n\nTreinamento concluído!\nModelo salvo com sucesso em: /kaggle/working/vit-fine-tuned-facial-expressions\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training_history(history):\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    # Converter tensores para CPU e depois para numpy (se necessário)\n    train_loss = history['train_loss'].cpu().numpy() if isinstance(history['train_loss'], torch.Tensor) else history['train_loss']\n    val_loss = history['val_loss'].cpu().numpy() if isinstance(history['val_loss'], torch.Tensor) else history['val_loss']\n    train_acc = history['train_acc'].cpu().numpy() if isinstance(history['train_acc'], torch.Tensor) else history['train_acc']\n    val_acc = history['val_acc'].cpu().numpy() if isinstance(history['val_acc'], torch.Tensor) else history['val_acc']\n    \n    plt.figure(figsize=(12, 5))\n    \n    # Plot da Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_loss, label='Treino - Loss', marker='o')\n    plt.plot(epochs, val_loss, label='Validação - Loss', marker='o')\n    plt.title('Loss ao longo das épocas')\n    plt.xlabel('Épocas')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot da Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_acc, label='Treino - Accuracy', marker='o')\n    plt.plot(epochs, val_acc, label='Validação - Accuracy', marker='o')\n    plt.title('Accuracy ao longo das épocas')\n    plt.xlabel('Épocas')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plotar o histórico de treinamento\nplot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T17:07:48.326669Z","iopub.execute_input":"2024-12-18T17:07:48.327075Z","iopub.status.idle":"2024-12-18T17:07:48.604502Z","shell.execute_reply.started":"2024-12-18T17:07:48.327039Z","shell.execute_reply":"2024-12-18T17:07:48.602927Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Plotar o histórico de treinamento\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m plot_training_history(\u001b[43mhistory\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}],"execution_count":3}]}